# LLM API Keys (Optional - use at least one)
GEMINI_API_KEY=your_gemini_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Ollama Configuration (Optional - for local models)
OLLAMA_BASE_URL=http://localhost:11434

# Model Configuration
DEFAULT_MODEL=gemini
GEMINI_MODEL=gemini-2.5-flash
GEMINI_EMBEDDING_MODEL=models/text-embedding-004
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
VECTOR_DIM=768
MAX_MEMORIES=1000
MEMORY_DECAY_DAYS=90
EMBEDDING_FALLBACK_ENABLED=false

# Reasoning Configuration
ENABLE_COT=true
MAX_REASONING_STEPS=5
MIN_CONFIDENCE_THRESHOLD=0.7

# Context Management
MAX_CONTEXT_TOKENS=4000
SHORT_TERM_MEMORY_SIZE=10

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=true
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# Security
SECRET_KEY=your_secret_key_here_change_in_production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Local Storage Path (all data stored here for privacy)
DATA_DIR=data
MEMORY_INDEX_PATH=data/memory_index.faiss
MEMORY_METADATA_PATH=data/memory_metadata.pkl

